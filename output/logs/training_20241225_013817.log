2024-12-25 01:38:17,813 - INFO - Logging to file: C:\Users\RodePeters\Desktop\chem_transformer\output\logs\training_20241225_013817.log
2024-12-25 01:38:19,311 - INFO - Script started...
2024-12-25 01:38:19,311 - INFO - Attempting to load dataset from: C:\Users\RodePeters\Desktop\chem_transformer\synth_data_h5\synthetic_dataset.h5
2024-12-25 01:38:19,312 - INFO - Folder exists: C:\Users\RodePeters\Desktop\chem_transformer\output
2024-12-25 01:38:19,312 - INFO - Folder exists: C:\Users\RodePeters\Desktop\chem_transformer\output\models
2024-12-25 01:38:19,313 - INFO - Folder exists: C:\Users\RodePeters\Desktop\chem_transformer\output\logs
2024-12-25 01:38:19,314 - INFO - Analyzing dataset...
2024-12-25 01:38:19,314 - INFO - Analyzing dataset at: C:\Users\RodePeters\Desktop\chem_transformer\synth_data_h5\synthetic_dataset.h5
2024-12-25 01:38:19,318 - INFO - Number of unique chemicals (output_dim_chemical): 3
2024-12-25 01:38:19,319 - INFO - Detecting sweep lengths...
2024-12-25 01:38:19,325 - INFO - Detected 300 sweeps.
2024-12-25 01:38:19,325 - INFO - Longest sweep length: 100
2024-12-25 01:38:19,326 - INFO - Adjusted features: 80 (with 5 padding)
2024-12-25 01:38:19,340 - INFO - Dataset Analysis:
2024-12-25 01:38:19,341 - INFO -   Number of features: 75
2024-12-25 01:38:19,341 - INFO -   Adjusted features: 80 (with 5 padding)
2024-12-25 01:38:19,341 - INFO -   Sequence length: 100
2024-12-25 01:38:19,341 - INFO -   Number of sweeps: 300
2024-12-25 01:38:19,342 - INFO -   Total Memory: 68.38 GB
2024-12-25 01:38:19,342 - INFO -   Available Memory: 47.76 GB
2024-12-25 01:38:19,342 - INFO -   Estimated max batch size by memory: 1492519
2024-12-25 01:38:19,343 - INFO -   Final batch size (limited by sweeps): 300
2024-12-25 01:38:19,343 - INFO - Dataset analysis complete:
  Adjusted Features: 80
  Padding Needed: 5
  Number of Features: 75
  Sequence Length: 100
  Batch Size: 300
  Number of Chemicals: 3
2024-12-25 01:38:19,344 - INFO - Initializing HDF5Dataset with file: C:\Users\RodePeters\Desktop\chem_transformer\synth_data_h5\synthetic_dataset.h5
2024-12-25 01:38:19,345 - INFO - Dataset initialized: 300 sweeps, sequence length 100, num chemicals 3.
2024-12-25 01:38:19,345 - INFO - Dataset loaded with 300 sweeps and sequence length 100.
2024-12-25 01:38:21,024 - INFO - MultiChemicalTransformer initialized:
  Input Dim: 80
  Num Heads: 10
  Num Layers: 2
  Dim Feedforward: 512
  Number of Chemicals: 3
2024-12-25 01:38:21,147 - INFO - Model initialized:
  Adjusted Features: 80
  Num Heads: 10
  Num Layers: 2
  Sequence Length: 100
  Number of Chemicals: 3
2024-12-25 01:38:21,148 - INFO - Starting training loop...
2024-12-25 01:38:21,149 - INFO - Splitting dataset: 240 training samples, 60 validation samples.
2024-12-25 01:38:23,213 - INFO - Epoch 1/1000 started...
2024-12-25 01:38:23,215 - DEBUG - Retrieving data for index 9...
2024-12-25 01:38:23,215 - DEBUG - Start index: 900, End index: 1000
2024-12-25 01:38:23,215 - DEBUG - Features shape: torch.Size([100, 75])
2024-12-25 01:38:23,215 - DEBUG - Padded features shape: torch.Size([100, 80])
2024-12-25 01:38:23,215 - DEBUG - Chemical indices: 0 Shape: torch.Size([])
2024-12-25 01:38:23,218 - DEBUG - Chemical (multi-hot): tensor([1., 0., 0.]) Shape: torch.Size([3])
2024-12-25 01:38:23,219 - DEBUG - Concentration: 10.0 Shape: torch.Size([])
2024-12-25 01:38:23,219 - DEBUG - Experiment number: 0
2024-12-25 01:38:23,219 - DEBUG - Frequency shape: torch.Size([100])
2024-12-25 01:38:23,219 - ERROR - Error in __getitem__ at index 9: Concentration vector should be 1D but got: torch.Size([])
Traceback (most recent call last):
  File "C:\Users\RodePeters\Desktop\chem_transformer\code\train_model\dataset.py", line 131, in __getitem__
    assert len(concentration.shape) == 1, (
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: Concentration vector should be 1D but got: torch.Size([])
2024-12-25 01:38:23,221 - ERROR - An error occurred during training: Concentration vector should be 1D but got: torch.Size([])
Traceback (most recent call last):
  File "C:\Users\RodePeters\Desktop\chem_transformer\code\train_model\train.py", line 97, in train_model
    for batch in train_loader:
  File "C:\Users\RodePeters\Anaconda3\envs\torch_env\Lib\site-packages\torch\utils\data\dataloader.py", line 701, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\RodePeters\Anaconda3\envs\torch_env\Lib\site-packages\torch\utils\data\dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RodePeters\Anaconda3\envs\torch_env\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 50, in fetch
    data = self.dataset.__getitems__(possibly_batched_index)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RodePeters\Anaconda3\envs\torch_env\Lib\site-packages\torch\utils\data\dataset.py", line 420, in __getitems__
    return [self.dataset[self.indices[idx]] for idx in indices]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RodePeters\Anaconda3\envs\torch_env\Lib\site-packages\torch\utils\data\dataset.py", line 420, in <listcomp>
    return [self.dataset[self.indices[idx]] for idx in indices]
            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RodePeters\Desktop\chem_transformer\code\train_model\dataset.py", line 131, in __getitem__
    assert len(concentration.shape) == 1, (
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: Concentration vector should be 1D but got: torch.Size([])
2024-12-25 01:38:23,230 - ERROR - An error occurred: Concentration vector should be 1D but got: torch.Size([])
Traceback (most recent call last):
  File "C:\Users\RodePeters\Desktop\chem_transformer\code\train_model\main.py", line 85, in main
    train_model(
  File "C:\Users\RodePeters\Desktop\chem_transformer\code\train_model\train.py", line 97, in train_model
    for batch in train_loader:
  File "C:\Users\RodePeters\Anaconda3\envs\torch_env\Lib\site-packages\torch\utils\data\dataloader.py", line 701, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "C:\Users\RodePeters\Anaconda3\envs\torch_env\Lib\site-packages\torch\utils\data\dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RodePeters\Anaconda3\envs\torch_env\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 50, in fetch
    data = self.dataset.__getitems__(possibly_batched_index)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RodePeters\Anaconda3\envs\torch_env\Lib\site-packages\torch\utils\data\dataset.py", line 420, in __getitems__
    return [self.dataset[self.indices[idx]] for idx in indices]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RodePeters\Anaconda3\envs\torch_env\Lib\site-packages\torch\utils\data\dataset.py", line 420, in <listcomp>
    return [self.dataset[self.indices[idx]] for idx in indices]
            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "C:\Users\RodePeters\Desktop\chem_transformer\code\train_model\dataset.py", line 131, in __getitem__
    assert len(concentration.shape) == 1, (
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: Concentration vector should be 1D but got: torch.Size([])
